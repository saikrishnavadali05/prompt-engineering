"use strict";(self.webpackChunkprompt_engineering=self.webpackChunkprompt_engineering||[]).push([[94],{7722:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"8-model-specific-prompt","title":"Model-specific Prompting","description":"Not all language models behave the same. Their capabilities, limitations, and syntax expectations can vary based on their architecture, training data, and interfaces. Tailoring prompts to the specific model you\'re working with improves results dramatically.","source":"@site/docs/8-model-specific-prompt.md","sourceDirName":".","slug":"/8-model-specific-prompt","permalink":"/prompt-engineering/docs/8-model-specific-prompt","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"id":"8-model-specific-prompt","title":"Model-specific Prompting","slug":"/8-model-specific-prompt"},"sidebar":"tutorialSidebar","previous":{"title":"Domain-specific Prompting","permalink":"/prompt-engineering/docs/7-domain-specific"},"next":{"title":"Tools & Frameworks","permalink":"/prompt-engineering/docs/9-tools-frameworks"}}');var i=s(4848),t=s(8453);const l={id:"8-model-specific-prompt",title:"Model-specific Prompting",slug:"/8-model-specific-prompt"},o="8. Prompt Engineering for Different Models",d={},a=[{value:"\ud83e\udd16 GPT Models (OpenAI)",id:"-gpt-models-openai",level:3},{value:"\ud83d\udd17 Claude (Anthropic)",id:"-claude-anthropic",level:3},{value:"\ud83e\udd99 LLaMA (Meta)",id:"-llama-meta",level:3},{value:"\ud83d\udc28 Koala / Alpaca / Vicuna (Fine-tuned LLaMA variants)",id:"-koala--alpaca--vicuna-fine-tuned-llama-variants",level:3},{value:"\ud83e\uddea Command R+ (Cohere) / Mistral / Mixtral / Gemini (Google)",id:"-command-r-cohere--mistral--mixtral--gemini-google",level:3},{value:"\ud83e\udde0 Key Differences Across Models",id:"-key-differences-across-models",level:3},{value:"\ud83c\udfaf Summary",id:"-summary",level:3}];function c(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"8-prompt-engineering-for-different-models",children:"8. Prompt Engineering for Different Models"})}),"\n",(0,i.jsxs)(n.p,{children:["Not all language models behave the same. Their capabilities, limitations, and syntax expectations can vary based on their ",(0,i.jsx)(n.strong,{children:"architecture"}),", ",(0,i.jsx)(n.strong,{children:"training data"}),", and ",(0,i.jsx)(n.strong,{children:"interfaces"}),". Tailoring prompts to the specific model you're working with improves results dramatically."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-gpt-models-openai",children:"\ud83e\udd16 GPT Models (OpenAI)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Extremely versatile and widely adopted."}),"\n",(0,i.jsxs)(n.li,{children:["Great for ",(0,i.jsx)(n.strong,{children:"natural conversations"}),", ",(0,i.jsx)(n.strong,{children:"code"}),", ",(0,i.jsx)(n.strong,{children:"summarization"}),", etc."]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"system prompts"})," to set context and behavior:"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\r\n  "system": "You are a helpful tutor.",\r\n  "user": "Explain quantum computing in simple terms."\r\n}\n'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Can handle ",(0,i.jsx)(n.strong,{children:"multi-turn dialogue"}),", few-shot examples, and long prompts."]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-claude-anthropic",children:"\ud83d\udd17 Claude (Anthropic)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["More focused on ",(0,i.jsx)(n.strong,{children:"harmlessness"}),", ",(0,i.jsx)(n.strong,{children:"helpfulness"}),", and ",(0,i.jsx)(n.strong,{children:"honesty"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Sensitive to tone and phrasing\u2014",(0,i.jsx)(n.strong,{children:"politeness helps"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Use clear instructions and high-context prompts."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"You're a kind assistant. What are some emotional benefits of journaling?\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-llama-meta",children:"\ud83e\udd99 LLaMA (Meta)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Usually requires ",(0,i.jsx)(n.strong,{children:"more direct"})," prompting."]}),"\n",(0,i.jsxs)(n.li,{children:["Works better with ",(0,i.jsx)(n.strong,{children:"few-shot"})," or ",(0,i.jsx)(n.strong,{children:"structured"})," prompts."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'Translate the following sentence from English to French: "Good morning!"\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-koala--alpaca--vicuna-fine-tuned-llama-variants",children:"\ud83d\udc28 Koala / Alpaca / Vicuna (Fine-tuned LLaMA variants)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Often fine-tuned for specific domains or roles."}),"\n",(0,i.jsxs)(n.li,{children:["May respond better to ",(0,i.jsx)(n.strong,{children:"instruction-following"})," formats."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"### Instruction:\r\nSummarize the following paragraph in bullet points.\r\n### Input:\r\n<paragraph text>\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-command-r-cohere--mistral--mixtral--gemini-google",children:"\ud83e\uddea Command R+ (Cohere) / Mistral / Mixtral / Gemini (Google)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Each model has unique strengths:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cohere"}),": Retrieval-augmented generation."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mistral"}),": Lightweight and multilingual."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gemini"}),": Tightly integrated with Google ecosystem."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["\u2705 Always refer to ",(0,i.jsx)(n.strong,{children:"API docs"})," or playgrounds for best prompt practices!"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-key-differences-across-models",children:"\ud83e\udde0 Key Differences Across Models"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"GPT-4"}),(0,i.jsx)(n.th,{children:"Claude"}),(0,i.jsx)(n.th,{children:"LLaMA"}),(0,i.jsx)(n.th,{children:"Gemini"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Multi-turn support"}),(0,i.jsx)(n.td,{children:"\u2705 Yes"}),(0,i.jsx)(n.td,{children:"\u2705 Yes"}),(0,i.jsx)(n.td,{children:"\u274c Limited"}),(0,i.jsx)(n.td,{children:"\u2705 Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Few-shot learning"}),(0,i.jsx)(n.td,{children:"\u2705 Strong"}),(0,i.jsx)(n.td,{children:"\u2705 Good"}),(0,i.jsx)(n.td,{children:"\u2705 OK"}),(0,i.jsx)(n.td,{children:"\u2705 Moderate"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Best for"}),(0,i.jsx)(n.td,{children:"General use"}),(0,i.jsx)(n.td,{children:"Safe replies"}),(0,i.jsx)(n.td,{children:"Custom apps"}),(0,i.jsx)(n.td,{children:"Google tools"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Access"}),(0,i.jsx)(n.td,{children:"API + Chat"}),(0,i.jsx)(n.td,{children:"API + Console"}),(0,i.jsx)(n.td,{children:"Local/API"}),(0,i.jsx)(n.td,{children:"API/Console"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"-summary",children:"\ud83c\udfaf Summary"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Choose the prompt style based on the model you're using."})}),"\n",(0,i.jsx)(n.p,{children:"The same prompt can yield drastically different results depending on the model."}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var r=s(6540);const i={},t=r.createContext(i);function l(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);